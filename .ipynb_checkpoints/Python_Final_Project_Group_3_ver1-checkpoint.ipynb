{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c4f655",
   "metadata": {},
   "source": [
    "# $$ Scientific \\text{ } Computing \\text{ } with \\text{ } Python: \\text{ } Group \\text{ } 3 \\text{ } Final \\text{ } Project $$\n",
    "# $$California \\text{ } Mall \\text{ } Customer \\text{ } Sales \\text{ } Analysis$$\n",
    "Due Time: December 11th\n",
    "\n",
    "Name: **Muyang Huang**, **Mian Jiang**\n",
    "\n",
    "Please turn in a report in Jupyter Notebook file containing\n",
    "- Python code with comments\n",
    "- Necessary Markdown write-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd4e10-2119-4b48-87b2-83078dc5099c",
   "metadata": {},
   "source": [
    "## 1. Introductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fac506d-9939-46a6-ac46-c64f45efb0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing some introductions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229c6b1b-6311-4439-af25-94122fa61691",
   "metadata": {},
   "source": [
    "This project aims to analyze and identify trends and insights in customer demographics, sales performance, and mall characteristics for shopping malls in major metropolitan regions across California (San Francisco, Los Angeles, and San Diego). By revealing the distribution and trend of consumption patterns in the area from 2021 to 2023, our findings might further provide valuable decision-making insights for governors and business owners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4686f1-1c73-4ce5-9044-20d175fd9b5b",
   "metadata": {},
   "source": [
    "## 2. Materials and Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be429f8a-baf4-4f9b-9fa7-c81e14059df2",
   "metadata": {},
   "source": [
    "### 2.1 Dataset Description\n",
    "\n",
    "California Mall Customer Sales Dataset from https://www.kaggle.com/datasets/captaindatasets/istanbul-mall\n",
    "\n",
    "1.\tSales Data: Contains transaction details such as invoice_no, customer_id, category, quantity, invoice date, price, and shopping_mall. This data allows us to analyze sales trends, product popularity, and mall performance.\n",
    "2.\tCustomer Data: Provides demographic information (customer_id, gender, age, and payment_method) to support customer segmentation and uncover demographic-based spending trends and payment preferences.\n",
    "3.\tShopping Mall Data: Describes mall characteristics like shopping_mall, construction_year, area_sqm, location, and stores_count, enable analyzing how mall attributes (size, age, location) influence customer traffic and sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67681788-cb10-471f-976d-0e3e92533a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "# import folium\n",
    "# from folium.plugins import HeatMap\n",
    "from scipy import stats\n",
    "from ipyleaflet import Map, Marker, CircleMarker\n",
    "from ipywidgets import SelectionSlider, VBox, interact\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ddca0ed-2607-4386-a095-5dc4e4b3b0d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/sales_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Loading the datasets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sales_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/sales_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m customer_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/customer_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m shopping_mall_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/shopping_mall_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jm\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\jm\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\jm\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\jm\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\jm\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/sales_data.csv'"
     ]
    }
   ],
   "source": [
    "# Loading the datasets\n",
    "sales_data = pd.read_csv('data/sales_data.csv')\n",
    "customer_data = pd.read_csv('data/customer_data.csv')\n",
    "shopping_mall_data = pd.read_csv('data/shopping_mall_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b436ba3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shopping_mall</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>area (sqm)</th>\n",
       "      <th>location</th>\n",
       "      <th>store_count</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South Coast Plaza</td>\n",
       "      <td>1967</td>\n",
       "      <td>250000</td>\n",
       "      <td>Costa Mesa</td>\n",
       "      <td>270</td>\n",
       "      <td>33.6910</td>\n",
       "      <td>-117.8890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Westfield Valley Fair</td>\n",
       "      <td>1986</td>\n",
       "      <td>220000</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>230</td>\n",
       "      <td>37.3255</td>\n",
       "      <td>-121.9456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Grove</td>\n",
       "      <td>2002</td>\n",
       "      <td>56000</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>140</td>\n",
       "      <td>34.0719</td>\n",
       "      <td>-118.3575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Westfield Century City</td>\n",
       "      <td>1964</td>\n",
       "      <td>133000</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>200</td>\n",
       "      <td>34.0587</td>\n",
       "      <td>-118.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beverly Center</td>\n",
       "      <td>1982</td>\n",
       "      <td>111000</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>160</td>\n",
       "      <td>34.0752</td>\n",
       "      <td>-118.3774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            shopping_mall  construction_year  area (sqm)     location  \\\n",
       "0       South Coast Plaza               1967      250000   Costa Mesa   \n",
       "1   Westfield Valley Fair               1986      220000  Santa Clara   \n",
       "2               The Grove               2002       56000  Los Angeles   \n",
       "3  Westfield Century City               1964      133000  Los Angeles   \n",
       "4          Beverly Center               1982      111000  Los Angeles   \n",
       "\n",
       "   store_count      lat       lon  \n",
       "0          270  33.6910 -117.8890  \n",
       "1          230  37.3255 -121.9456  \n",
       "2          140  34.0719 -118.3575  \n",
       "3          200  34.0587 -118.4190  \n",
       "4          160  34.0752 -118.3774  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shopping_mall_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b6b46-5312-4817-95b1-cdc6be571d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The names of the variables and the corresponding number of missing values in the seles data:\n",
      "invoice_no       0\n",
      "customer_id      0\n",
      "category         0\n",
      "quantity         0\n",
      "invoice date     0\n",
      "price            0\n",
      "shopping_mall    0\n",
      "dtype: int64\n",
      "\n",
      "The names of the variables and the corresponding number of missing values in the customer data:\n",
      "customer_id         0\n",
      "gender              0\n",
      "age               119\n",
      "payment_method      0\n",
      "dtype: int64\n",
      "\n",
      "The names of the variables and the corresponding number of missing values in the shopping mall data:\n",
      "shopping_mall        0\n",
      "construction_year    0\n",
      "area (sqm)           0\n",
      "location             0\n",
      "store_count          0\n",
      "lat                  0\n",
      "lon                  0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Handling Missing Data\n",
    "# Identify missing values\n",
    "print(\"The names of the variables and the corresponding number of missing values in the seles data:\")\n",
    "print(sales_data.isnull().sum())\n",
    "print(\"\")\n",
    "print(\"The names of the variables and the corresponding number of missing values in the customer data:\")\n",
    "print(customer_data.isnull().sum())\n",
    "print(\"\")\n",
    "print(\"The names of the variables and the corresponding number of missing values in the shopping mall data:\")\n",
    "print(shopping_mall_data.isnull().sum())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4674672-d6fa-4d1c-88f2-6a6a1957eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing some descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f321033d-7d1b-4922-acb4-ab0855280bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing numerical values with median\n",
    "customer_data['age'] = customer_data['age'].fillna(customer_data['age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e56773-0dc0-4a20-a3a3-756b7ae94515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing some descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c87c01-ab35-4aa9-95bc-4daa873d482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers using IQR\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "sales_data_without_outliers = remove_outliers(sales_data, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bef57d-09b0-4dce-b6ee-1f55ac7961f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 94433 entries, 0 to 99456\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   invoice_no     94433 non-null  object \n",
      " 1   customer_id    94433 non-null  object \n",
      " 2   category       94433 non-null  object \n",
      " 3   quantity       94433 non-null  int64  \n",
      " 4   invoice date   94433 non-null  object \n",
      " 5   price          94433 non-null  float64\n",
      " 6   shopping_mall  94433 non-null  object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 5.8+ MB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99457 entries, 0 to 99456\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   customer_id     99457 non-null  object \n",
      " 1   gender          99457 non-null  object \n",
      " 2   age             99457 non-null  float64\n",
      " 3   payment_method  99457 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   shopping_mall      10 non-null     object \n",
      " 1   construction_year  10 non-null     int64  \n",
      " 2   area (sqm)         10 non-null     int64  \n",
      " 3   location           10 non-null     object \n",
      " 4   store_count        10 non-null     int64  \n",
      " 5   lat                10 non-null     float64\n",
      " 6   lon                10 non-null     float64\n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 692.0+ bytes\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary of cleaned datasets\n",
    "print(sales_data_without_outliers.info())\n",
    "print(\"\")\n",
    "print(customer_data.info())\n",
    "print(\"\")\n",
    "print(shopping_mall_data.info())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baada7f0-6c27-4a33-a284-04d95360974c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aaba68-250e-4347-bda9-c862512fc9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Shapiro-Wilk Test (scipy.stats.shapiro) to test the null hypothesis that the data is normally distributed.\n",
    "# Do we really need that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c83dc2-ae26-4de0-ba71-f80bcf895017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a77d45-17d4-43f3-9122-040166e822aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned datasets\n",
    "sales_data_without_outliers.to_csv('data_cleaned/cleaned_sales_data.csv', index=False)\n",
    "customer_data.to_csv('data_cleaned/cleaned_customer_data.csv', index=False)\n",
    "shopping_mall_data.to_csv('data_cleaned/cleaned_shopping_mall_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173ced6-dfba-4386-bd77-eb5d1ea8edb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SelectionSlider' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m m \u001b[38;5;241m=\u001b[39m Map(center\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m36.7783\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m119.4179\u001b[39m), zoom\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 创建滑动条\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m slider \u001b[38;5;241m=\u001b[39m SelectionSlider(\n\u001b[0;32m     17\u001b[0m     options\u001b[38;5;241m=\u001b[39mdates,\n\u001b[0;32m     18\u001b[0m     value\u001b[38;5;241m=\u001b[39mdates[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     19\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m     continuous_update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 创建动态更新函数\u001b[39;00m\n\u001b[0;32m     24\u001b[0m circles \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# 用于存储地图上的 CircleMarker 对象\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SelectionSlider' is not defined"
     ]
    }
   ],
   "source": [
    "# Exploratory display of the sales data\n",
    "sales_data[\"invoice date\"] = pd.to_datetime(sales_data[\"invoice date\"])\n",
    "sale_date = sales_data.groupby([\"shopping_mall\", \"invoice date\"], as_index=False)[\"price\"].sum()\n",
    "sale_with_coord = pd.merge(sale_date, shopping_mall_data, how='left', on='shopping_mall')[['shopping_mall', 'invoice date', 'price', 'lon', 'lat']]\n",
    "\n",
    "# 提取所有日期\n",
    "dates = sorted(sale_with_coord[\"invoice date\"].dt.strftime(\"%Y-%m-%d\").unique())\n",
    "\n",
    "# 获取每个x的经纬度\n",
    "locations = sale_with_coord.groupby('shopping_mall')[[\"lat\", \"lon\"]].first().reset_index()\n",
    "\n",
    "# 创建地图\n",
    "m = Map(center=(36.7783, -119.4179), zoom=6)\n",
    "\n",
    "# 创建滑动条\n",
    "slider = SelectionSlider(\n",
    "    options=dates,\n",
    "    value=dates[0],\n",
    "    description=\"Date:\",\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "# 创建动态更新函数\n",
    "circles = {}  # 用于存储地图上的 CircleMarker 对象\n",
    "\n",
    "def update_map(selected_date):\n",
    "    # 清理旧的 CircleMarker\n",
    "    for circle in circles.values():\n",
    "        m.remove_layer(circle)\n",
    "    circles.clear()\n",
    "    \n",
    "    # 获取选中日期的汇总数据\n",
    "    current_data = sale_with_coord[sale_with_coord[\"invoice date\"] == pd.to_datetime(selected_date)]\n",
    "    for _, row in current_data.iterrows():\n",
    "        x = row[\"shopping_mall\"]\n",
    "        z_value = row[\"price\"]\n",
    "        loc = locations[locations[\"shopping_mall\"] == x]\n",
    "        latitude = loc[\"lat\"].values[0]\n",
    "        longitude = loc[\"lon\"].values[0]\n",
    "\n",
    "        # 创建 CircleMarker\n",
    "        circle = CircleMarker(\n",
    "            location=(latitude, longitude),\n",
    "            radius=int(z_value / 1000),  # 根据z值调整圆的大小\n",
    "            color=\"blue\",\n",
    "            fill_color=\"blue\",\n",
    "            fill_opacity=0.7,\n",
    "            #popup=f\"{x}: {z_value}\"\n",
    "        )\n",
    "        circles[x] = circle\n",
    "        m.add_layer(circle)\n",
    "\n",
    "# 滑动条事件绑定\n",
    "def on_slider_change(change):\n",
    "    update_map(change[\"new\"])\n",
    "\n",
    "slider.observe(on_slider_change, names=\"value\")\n",
    "\n",
    "# 显示初始地图和滑动条\n",
    "update_map(dates[0])  # 初始化地图\n",
    "\n",
    "# interact(lambda index: update_map(index), index=slider)\n",
    "VBox([slider, m])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223eea0c-88eb-4467-9b22-31a19ddf6263",
   "metadata": {},
   "source": [
    "### 2.2 Hypotheses\n",
    "To achieve our objective, we propose conducting hypothesis testing regarding the following perspectives:\n",
    "\n",
    "#### Geographical Divergence\n",
    "$H_0$: All of the malls from different metropolitan areas were performing the same throughout the whole period?\\\n",
    "$H_a$: At least one of the malls from different metropolitan areas were performing differently throughout the whole period?\n",
    "\n",
    "#### Seasonality\n",
    "$H_0$: The behavior of consumption was invariant on different days (seasons, holidays, incidents) of a year?\\\n",
    "$H_a$: The behavior of consumption was not invariant on different days (seasons, holidays, incidents) of a year?\n",
    "\n",
    "#### Consumer Behavior\n",
    "$H_0$: The customers’ consumption is independent of demographic and economic attributes.\\\n",
    "$H_a$: The customers’ consumption is not independent of demographic and economic attributes.\n",
    "\n",
    "### 2.3 Data Manipulation and Visualization Techniques\n",
    "\n",
    "- Clean unreasonable and missing data. Ensure consistency in addressing categories for categorical variables.\n",
    "- Filter outliers. Take the logarithm of sales depending on normality.\n",
    "- Visualize daily sales trends over time across different malls in the Sales table using line charts.\n",
    "- Merge the Sales and Customer tables by customer_id and create pairwise scatter plots to visualize relationships between spending and explanation variables like the attributes of the mall and customer’s demographic factors.\n",
    "- Merge the Sales and Shopping Mall tables and, using geographic data, visualize sales figures on a California map in the form of heatmaps or other appropriate visualizations.\n",
    "\n",
    "### 2.4 Statistical Tests\n",
    "\n",
    "1.\tConduct a hypothesis test on the mean value of figures from shopping malls in different metropolitan areas. A possible approach is a two-sample t-test implemented by stats.ttest_ind.\n",
    "2.\tConduct a hypothesis test on sales for the same mall across different months or years. A possible approach is association tests implemented by stats.f_oneway.\n",
    "3.\tDevelop a predictive model for customer spending based on mall-specific information and customers’ demographic attributes. A possible approach is a linear regression model implemented by stats.lingress.\n",
    "\n",
    "### 2.3 Statistical Tests\n",
    "We would like to apply time series approaches to study the nature of the consumption data like stationarity and causal structure to gain a deeper understanding of the story lying behind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e29147-9a17-4ef8-b62b-557226de5db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a1e67c5-6465-47d7-b682-7fe422d3d148",
   "metadata": {},
   "source": [
    "## 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2b285c-9c9c-4036-8324-74ccd9e8cfc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdca3d7e-1a72-482c-8662-434bd988378f",
   "metadata": {},
   "source": [
    "Visualize daily sales trends over time across different malls in the Sales table using line charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e647fa8-fa20-4816-ad19-43666d93ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an explicit copy before modification to avoid the warning\n",
    "sales_data_without_outliers = sales_data_without_outliers.copy()\n",
    "# Convert the 'invoice_date' column to datetime\n",
    "sales_data_without_outliers.loc[:, 'invoice_date'] = pd.to_datetime(sales_data_without_outliers['invoice date'])\n",
    "\n",
    "# Group by mall and date\n",
    "daily_sales_quantity = (\n",
    "    sales_data_without_outliers.groupby(['shopping_mall', 'invoice_date'])\n",
    "    .agg(total_sales=('quantity', 'sum'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Plot daily sales trends\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.lineplot(\n",
    "    data=daily_sales_quantity, \n",
    "    x='invoice_date', \n",
    "    y='total_sales', \n",
    "    hue='shopping_mall',\n",
    "    marker='o',\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Daily Sales Quantities Across Different Malls', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Total Sales Quantities', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Shopping Mall', fontsize=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2dc7e-6dec-4837-b0c9-e8c8d6aa540e",
   "metadata": {},
   "source": [
    "No obvisous trend, but Del Amo Fashion Center, South Coast Plaza, and Westfield Century City are tend to have more sales quantities throughout the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9544e1-8aa6-44b7-9bad-040de8e75c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88290f9-c9f4-4fea-9c03-cb5c850f9a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36ec31f7-32f6-4679-95f4-aa00552bdafc",
   "metadata": {},
   "source": [
    "Merge the Sales and Customer tables by customer_id and create pairwise scatter plots to visualize relationships between spending and explanation variables like the attributes of the mall and customer’s demographic factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea6a5f-f7eb-45c4-bdc0-f6e4f8049889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables directly on the copy with .loc\n",
    "sales_data_without_outliers = sales_data_without_outliers.copy() # Make an explicit copy to avoid warnings\n",
    "\n",
    "# Calculate total spending per transaction\n",
    "sales_data_without_outliers['spending'] = sales_data_without_outliers['quantity'] * sales_data_without_outliers['price']\n",
    "\n",
    "# Merge Sales and Customer tables on 'customer_id'\n",
    "merged_data = pd.merge(sales_data_without_outliers, customer_data, on='customer_id', how='inner')\n",
    "\n",
    "# Select columns and convert categorical variables directly\n",
    "scatter_data = merged_data[[\n",
    "    'spending',       # Target variable: spending\n",
    "    'age',            # Customer demographic\n",
    "    'gender',         # Customer demographic (categorical)\n",
    "    'payment_method', # Customer demographic (categorical)\n",
    "    'shopping_mall'   # Mall variable (categorical)\n",
    "]].copy()  # Explicitly create a copy to avoid the warning\n",
    "\n",
    "# Encoding categorical variables for visualization\n",
    "scatter_data.loc[:, 'gender'] = scatter_data['gender'].astype('category')\n",
    "scatter_data.loc[:, 'payment_method'] = scatter_data['payment_method'].astype('category')\n",
    "scatter_data.loc[:, 'shopping_mall'] = scatter_data['shopping_mall'].astype('category')\n",
    "\n",
    "# Visualize pairwise relationships\n",
    "sns.pairplot(\n",
    "    scatter_data,\n",
    "    diag_kind='kde',  # Kernel Density Estimation on diagonal\n",
    "    hue='gender',     # Color points by gender\n",
    "    palette='Set2',   # Color palette for clarity\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.suptitle(\"Pairwise Scatter Plots: Spending vs. Demographics and Mall Attributes\", y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f4c6d8-ffa6-4522-9cf1-122a0b5c5144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be855f14-5989-40d4-8d3b-ee4c0d18bee0",
   "metadata": {},
   "source": [
    "? Merge the Sales and Shopping Mall tables and, using geographic data, visualize sales figures on a California map in the form of heatmaps or other appropriate visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837e5586-e2ac-49fd-933d-124061ba751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Sales and Shopping Mall tables on 'shopping_mall'\n",
    "merged_data = pd.merge(sales_data_without_outliers, shopping_mall_data, on='shopping_mall', how='inner')\n",
    "\n",
    "# Aggregate total sales by shopping mall\n",
    "sales_by_mall = merged_data.groupby(['shopping_mall', 'location'])['spending'].sum().reset_index()\n",
    "\n",
    "# # Add approximate geographic coordinates for each location\n",
    "# mall_coordinates = {\n",
    "#     'San Francisco': [37.7749, -122.4194], # Replace with actual lat/lon\n",
    "#     'Los Angeles': [34.0522, -118.2437], # Replace with actual lat/lon\n",
    "#     'San Diego': [32.7157, -117.1611], # Replace with actual lat/lon\n",
    "#     # Add coordinates for other cities as needed\n",
    "# }.copy()\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8f4f6-c6da-4990-af45-586d7efcc2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01aa3fd6-e77a-45e7-9252-1f8a52fa005c",
   "metadata": {},
   "source": [
    "Conduct a hypothesis test on the mean value of figures from shopping malls in different metropolitan areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d16eb-cb5e-4f8f-803c-43b8541783b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for two metropolitan areas\n",
    "cm_sales = sales_by_mall[sales_by_mall['location'] == 'Costa Mesa']['spending']\n",
    "tor_sales = sales_by_mall[sales_by_mall['location'] == 'Torrance']['spending']\n",
    "\n",
    "# # Check for normality\n",
    "# _, cm_pvalue_normality = stats.shapiro(cm_sales)\n",
    "# _, tor_pvalue_normality = stats.shapiro(tor_sales)\n",
    "\n",
    "# print(f\"Costa Mesa sales normality test p-value: {cm_pvalue_normality}\")\n",
    "# print(f\"Torrance sales normality test p-value: {tor_pvalue_normality}\")\n",
    "\n",
    "# # Check for equal variances\n",
    "# _, pvalue_var_equal = stats.levene(cm_sales, tor_sales)\n",
    "# print(f\"Levene's test p-value for equal variance: {pvalue_var_equal}\")\n",
    "\n",
    "# # Perform the two-sample t-test\n",
    "# equal_var = pvalue_var_equal > 0.05  # Assume equal variance if Levene's test p-value > 0.05\n",
    "# t_stat, p_value = stats.ttest_ind(cm_sales, tor_sales, equal_var=equal_var)\n",
    "\n",
    "# print(\"\\nT-Test Results:\")\n",
    "# print(f\"t-statistic: {t_stat}\")\n",
    "# print(f\"p-value: {p_value}\")\n",
    "\n",
    "# # Interpretation\n",
    "# alpha = 0.05\n",
    "# if p_value < alpha:\n",
    "#     print(\"Reject the null hypothesis: There is a significant difference in mean sales figures.\")\n",
    "# else:\n",
    "#     print(\"Fail to reject the null hypothesis: No significant difference in mean sales figures.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7c3c4-d876-40f2-bac2-7788ca6e9261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1cc99b3-76b4-428c-b3ba-81bf973ff48a",
   "metadata": {},
   "source": [
    "Conduct a hypothesis test on sales for the same mall across different months or years. A possible approach is association tests implemented by stats.f_oneway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699dbbde-c14a-4fb1-a9e6-12cd426feee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23105fc7-8bc6-4aad-8864-a0f1ede7b67a",
   "metadata": {},
   "source": [
    "Develop a predictive model for customer spending based on mall-specific information and customers’ demographic attributes. A possible approach is a linear regression model implemented by stats.lingress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd03e16-1218-4811-9941-053191d03bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0249338-1340-4389-b328-23f8e3d906bf",
   "metadata": {},
   "source": [
    "## 4. Discussions and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f40c0ac-b32d-4503-9d8f-27709f6a92d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acbcbeff-b160-4a11-9476-67e5e7ae799d",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a9b20-6e5d-4da0-9875-7c87852a98a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c32602f-b497-4d58-96a8-863de492905c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cfd9f2-d6e1-49fd-99b0-02275c21a276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded9e47b-b08e-4fb4-91f9-453b8b2ab821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db9673-d17a-4dd0-8228-c142ee59df60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8580dc2-f3a4-4944-b22f-2c39f7439406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86944559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3948fcbf-b19e-4b16-97b8-c0a0f5e61962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
